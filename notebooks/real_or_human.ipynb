{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436d0296-0adc-411d-a698-4c5c8f936ebc",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'Python 3.13.3'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. WebSocket is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8314c04-fbdd-44ad-9cb0-ed57e2ab92cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human dataset1:  Index(['image_id', '5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive',\n",
      "       'Bags_Under_Eyes', 'Bald', 'Bangs', 'Big_Lips', 'Big_Nose',\n",
      "       'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', 'Bushy_Eyebrows',\n",
      "       'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', 'Gray_Hair',\n",
      "       'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open',\n",
      "       'Mustache', 'Narrow_Eyes', 'No_Beard', 'Oval_Face', 'Pale_Skin',\n",
      "       'Pointy_Nose', 'Receding_Hairline', 'Rosy_Cheeks', 'Sideburns',\n",
      "       'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings',\n",
      "       'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace',\n",
      "       'Wearing_Necktie', 'Young'],\n",
      "      dtype='object')\n",
      "\n",
      "Human dataset2:  Index(['image_id', 'x_1', 'y_1', 'width', 'height'], dtype='object')\n",
      "\n",
      "Human dataset3:  Index(['image_id', 'partition'], dtype='object')\n",
      "\n",
      "Human dataset4:  Index(['image_id', 'lefteye_x', 'lefteye_y', 'righteye_x', 'righteye_y',\n",
      "       'nose_x', 'nose_y', 'leftmouth_x', 'leftmouth_y', 'rightmouth_x',\n",
      "       'rightmouth_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "human_data1 = pd.read_csv(\"../datasets/human/list_attr_celeba.csv\")\n",
    "human_data2 = pd.read_csv(\"../datasets/human/list_bbox_celeba.csv\")\n",
    "human_data3 = pd.read_csv(\"../datasets/human/list_eval_partition.csv\")\n",
    "human_data4 = pd.read_csv(\"../datasets/human/list_landmarks_align_celeba.csv\")\n",
    "\n",
    "print(\"Human dataset1: \", human_data1.columns)\n",
    "print(\"\\nHuman dataset2: \", human_data2.columns)\n",
    "print(\"\\nHuman dataset3: \", human_data3.columns)\n",
    "print(\"\\nHuman dataset4: \", human_data4.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5e3c0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI dataset:  Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,     9,\n",
      "       ...\n",
      "       69990, 69991, 69992, 69993, 69994, 69995, 69996, 69997, 69998, 69999],\n",
      "      dtype='int64', length=70000)\n"
     ]
    }
   ],
   "source": [
    "ai_datasets = pd.read_json(\"../datasets/ai/ffhq-dataset-v1-processed.json\")\n",
    "\n",
    "print(\"\\nAI dataset: \", ai_datasets.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "addbbb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged dataset:       image_id  5_o_Clock_Shadow  Arched_Eyebrows  Attractive  Bags_Under_Eyes  \\\n",
      "0  000001.jpg                -1                1           1               -1   \n",
      "1  000002.jpg                -1               -1          -1                1   \n",
      "2  000003.jpg                -1               -1          -1               -1   \n",
      "3  000004.jpg                -1               -1           1               -1   \n",
      "4  000005.jpg                -1                1           1               -1   \n",
      "\n",
      "   Bald  Bangs  Big_Lips  Big_Nose  Black_Hair  ...  lefteye_x  lefteye_y  \\\n",
      "0    -1     -1        -1        -1          -1  ...         69        109   \n",
      "1    -1     -1        -1         1          -1  ...         69        110   \n",
      "2    -1     -1         1        -1          -1  ...         76        112   \n",
      "3    -1     -1        -1        -1          -1  ...         72        113   \n",
      "4    -1     -1         1        -1          -1  ...         66        114   \n",
      "\n",
      "   righteye_x  righteye_y  nose_x  nose_y  leftmouth_x  leftmouth_y  \\\n",
      "0         106         113      77     142           73          152   \n",
      "1         107         112      81     135           70          151   \n",
      "2         104         106     108     128           74          156   \n",
      "3         108         108     101     138           71          155   \n",
      "4         112         112      86     119           71          147   \n",
      "\n",
      "   rightmouth_x  rightmouth_y  \n",
      "0           108           154  \n",
      "1           108           153  \n",
      "2            98           158  \n",
      "3           101           151  \n",
      "4           104           150  \n",
      "\n",
      "[5 rows x 56 columns]\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(human_data1, human_data2, on='image_id').merge(human_data3, on='image_id').merge(human_data4, on='image_id')\n",
    "\n",
    "print(\"\\nMerged dataset: \", merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b14967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"label\"] = 0 # 0 for real human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "353c6f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_df = pd.DataFrame({\n",
    "    \"image_id\" : [f\"{i}.png\" for i in range(len(ai_datasets))],\n",
    "    \"label\" : 1 # 1 for AI generated\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd29187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_df = merged_df[[\"image_id\", \"label\"]]\n",
    "combined_df = pd.concat([human_df, ai_df], ignore_index=True)\n",
    "combined_df = combined_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72a6dbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c62dc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None, root_dir=\"../datasets\"):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        img_name = row[\"image_id\"]\n",
    "        label = row[\"label\"]\n",
    "\n",
    "        if label == 0:\n",
    "            img_path = os.path.join(self.root_dir, \"human\", \"img_align_celeba\", img_name)\n",
    "        else:\n",
    "            img_path = os.path.join(self.root_dir, \"ai\", \"faces_dataset\", img_name)\n",
    "        \n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ea11678",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(combined_df, test_size=0.2, stratify=combined_df['label'], random_state=42)\n",
    "\n",
    "train_dataset = ImageDataset(train_df, transform=transform)\n",
    "val_dataset = ImageDataset(val_df, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b3e6738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "445b08de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32 * 16 * 16, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)  # Binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # -> [16, 32, 32]\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # -> [32, 16, 16]\n",
    "        x = x.view(-1, 32 * 16 * 16)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c129a35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN().to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa84ca36",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'Python 3.11.0'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. WebSocket is not defined"
     ]
    }
   ],
   "source": [
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d350e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.float().unsqueeze(1).to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    accuracy = correct / total\n",
    "    return total_loss / len(loader), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fe34b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3473be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_epochs = 15\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_accuracy = validate(model, val_loader, criterion)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43580b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Loss Curves\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss over Epochs\")\n",
    "plt.legend()\n",
    "\n",
    "# Plot Accuracy Curve\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\", color='green')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Validation Accuracy over Epochs\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b949a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"simple_cnn_real_vs_ai.pth\")\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d276b4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def predict_image(image_path, model, transform):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        prediction = (output > 0.5).float()\n",
    "\n",
    "    if prediction.item() == 0:\n",
    "        print(f\"Prediction: Real Human Image 🧑‍🦰\")\n",
    "    else:\n",
    "        print(f\"Prediction: AI Generated Image 🤖\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d44bce0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
